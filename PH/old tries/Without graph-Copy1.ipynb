{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_parallel in_splits {'a': [<tf.Tensor 'split_23:0' shape=(2,) dtype=string>, <tf.Tensor 'split_23:1' shape=(2,) dtype=string>], 'b': [<tf.Tensor 'split_24:0' shape=(2,) dtype=string>, <tf.Tensor 'split_24:1' shape=(2,) dtype=string>]}\n",
      "0\n",
      "fff {'a': <tf.Tensor 'split_23:0' shape=(2,) dtype=string>, 'b': <tf.Tensor 'split_24:0' shape=(2,) dtype=string>}\n",
      "In Model GPU A:  Tensor(\"split_23:0\", shape=(2,), dtype=string)\n",
      "In Model GPU B:  Tensor(\"split_24:0\", shape=(2,), dtype=string)\n",
      "1\n",
      "fff {'a': <tf.Tensor 'split_23:1' shape=(2,) dtype=string>, 'b': <tf.Tensor 'split_24:1' shape=(2,) dtype=string>}\n",
      "In Model GPU A:  Tensor(\"split_23:1\", shape=(2,), dtype=string)\n",
      "In Model GPU B:  Tensor(\"split_24:1\", shape=(2,), dtype=string)\n",
      "make_parallel out_split [['0'], ['Finshed Model'], ['Finshed Total'], ['1'], ['Finshed Model'], ['Finshed Total']]\n",
      "Start Time 1512379911.501111 6.725738\n",
      "C [b'0' b'Finshed Model' b'Finshed Total' b'1' b'Finshed Model'\n",
      " b'Finshed Total']\n",
      "End Time 1512379911.5227957 6.746175\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "a=[\"A\",\"B\",\"C\",\"D\"]\n",
    "b=[\"1\",\"2\",\"3\",\"4\"]\n",
    "#a = tf.random_uniform([1000, 100])\n",
    "#b = tf.random_uniform([1000, 100])\n",
    "def model(a,b):\n",
    "    #print(\"In Model GPU: \",i)\n",
    "    print(\"In Model GPU A: \",a)\n",
    "    print(\"In Model GPU B: \",b)\n",
    "    c=a+b\n",
    "    return [\"Finshed Model\"]#c#a+b #\"In GPU:\"#+str(a)+\" \"+str(b)#+str(i)\n",
    "\n",
    "\n",
    "def make_parallel(fn, num_gpus, **kwargs):\n",
    "\n",
    "\n",
    "    in_splits = {}\n",
    "    for k, v in kwargs.items():\n",
    "        in_splits[k] = tf.split(v, num_gpus)\n",
    "    print(\"make_parallel in_splits\", in_splits)\n",
    "    out_split = []\n",
    "    for i in range(num_gpus):\n",
    "        print(i)\n",
    "        #with tf.device(tf.DeviceSpec(device_type=\"CPU\", device_index=i)):\n",
    "            #with tf.variable_scope(tf.get_variable_scope(), reuse=i > 0):\n",
    "        print(\"fff\",{k : v[i] for k, v in in_splits.items()})\n",
    "        out_split.append([str(i)])\n",
    "        out_split.append(fn(**{k : v[i] for k, v in in_splits.items()}))\n",
    "        out_split.append([\"Finshed Total\"])\n",
    "        \n",
    "    print(\"make_parallel out_split\",out_split)\n",
    "    \n",
    "    return tf.concat(out_split, axis=0)\n",
    "#c = make_parallel(model, 2, a=a, b=b)\n",
    "c = make_parallel(model, 2, a=a, b=b)\n",
    "#tf.summary.FileWriter(\"/home/fsg/logs_tf\", g).close()\n",
    "\n",
    "\n",
    "#with tf.device(tf.DeviceSpec(device_type=\"CPU\", device_index=0)):\n",
    "#a = tf.random_uniform([1000, 100])\n",
    "#b = tf.random_uniform([1000, 100])\n",
    "    #c = a + b\n",
    "\n",
    "\n",
    "\n",
    "config = tf.ConfigProto(device_count={\"GPU\": 2,\"CPU\":1},\n",
    "                        allow_soft_placement=True,\n",
    "                        inter_op_parallelism_threads=16,\n",
    "                        intra_op_parallelism_threads=16,\n",
    "                        use_per_session_threads=True,\n",
    "                        log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "print(\"Start Time\",time.time(), time.clock())\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print(\"C\",sess.run(c))\n",
    "#tf.summary.FileWriter(\"/home/fsg/logs_tf\", g).close()\n",
    "\n",
    "\n",
    "print(\"End Time\",time.time(), time.clock())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=[\"A\",\"B\",\"C\",\"D\",\"hh\"]\n",
    "GPU_NO=4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chunkIt(seq, num):\n",
    "    avg = len(seq) / float(num)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "\n",
    "    while last < len(seq):\n",
    "        out.append(seq[int(last):int(last + avg)])\n",
    "        last += avg\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['A'], ['B'], ['C'], ['D', 'hh']]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunkIt(a, GPU_NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "    #return [x.name for x in local_device_protos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "#import threading\n",
    "import timeit\n",
    "from tensorflow.python.client import timeline\n",
    "with tf.Session(config=config,graph=g) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    GPU_LIST=[]\n",
    "    list_file_gpu=[]\n",
    "    with tf.device('/cpu'):\n",
    "        print(\"Start Time\",time.time(), time.clock())\n",
    "        start = timeit.default_timer()\n",
    "        GPU_LIST=get_available_gpus()\n",
    "        list_file_gpu=chunkIt(a,len(GPU_LIST))\n",
    "        for i in range(len(GPU_LIST)):\n",
    "            with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=i)):\n",
    "                #gpu_full_process(file_names,path_data_base,path_tf,path_non_redundant,path_idf,file_path_sim)\n",
    "                #Your statements here\n",
    "\n",
    "        stop = timeit.default_timer()\n",
    "        print(\"End Time\",time.time(), time.clock())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
