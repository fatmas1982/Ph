{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#! /usr/bin/python3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=[\"A\",\"B\",\"C\",\"D\",\"hh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chunkIt(seq, num):\n",
    "   \n",
    "    avg = len(seq) / float(num)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "    if num > 1:\n",
    "        while last < len(seq):\n",
    "            out.append(seq[int(last):int(last + avg)])\n",
    "            last += avg\n",
    "    else:\n",
    "        return seq\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model(a_list,i):\n",
    "    print(\"list model\",a_list,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "    #return [x.name for x in local_device_protos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU.stats GPUStatCollection(host=fsg-Satellite-P750, [\n",
      "  \u001b[36m[0]\u001b[m \u001b[34mGeForce GT 540M \u001b[m |\u001b[1m\u001b[31m 63'C\u001b[m, \u001b[1m\u001b[30m ?? %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  279\u001b[m / \u001b[33m  964\u001b[m MB | (Not Supported)\n",
      "])\n",
      "setGPU.stats 0\n",
      "setGPU.ratios <map object at 0x7fb36d46f4e0>\n",
      "setGPU.ids <map object at 0x7fb36d442fd0>\n",
      "Start Time CPU 1512480856.8311646 30.410207\n",
      "['A', 'B', 'C', 'D', 'hh']\n",
      "Start Time GPU 0 Time is  1512480856.8318973 30.411237\n",
      "In GPU Dev 0\n",
      "list model A 0\n",
      "End Time GPU 0 Time is  1512480856.8332317 30.413104\n",
      "total_time_GPU 0.0013344287872314453\n",
      "total_clock_GPU 0.0018670000000007292\n",
      "End Time 1512480856.833459 30.413492\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '[Not Supported]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-9121db5128ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"End Time\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mGPU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowUtilization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mtl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_chrome_trace_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPUtil/__init__.py\u001b[0m in \u001b[0;36mshowUtilization\u001b[0;34m(all)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshowUtilization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0mGPUs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetGPUs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' ID | Name | Serial || GPU util. | Memory util. || Memory total | Memory used | Memory free || Display mode | Display active |'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPUtil/__init__.py\u001b[0m in \u001b[0;36mgetGPUs\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mdeviceIds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mgpuUtil\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mmemTotal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '[Not Supported]'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "import tensorflow as tf\n",
    "#import threading\n",
    "import timeit\n",
    "import time\n",
    "#from tensorflow import logging\n",
    "from tensorflow.python.client import timeline\n",
    "#os.environ['TF_CPP_MIN_VLOG_LEVEL']='3'\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "#logging.set_verbosity(logging.INFO)\n",
    "#logging.vlog(1, \"Registering %s (%s) in %s.\", name, candidate, self._name)\n",
    "\n",
    "config = tf.ConfigProto(device_count={\"GPU\": 2,\"CPU\":1},\n",
    "                        allow_soft_placement=True,\n",
    "                        inter_op_parallelism_threads=16,\n",
    "                        intra_op_parallelism_threads=16,\n",
    "                        use_per_session_threads=True,\n",
    "                        log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "import setGPU\n",
    "print(\"setGPU.stats\",setGPU.stats)\n",
    "print(\"setGPU.stats\",setGPU.bestGPU)\n",
    "print(\"setGPU.ratios\",setGPU.ratios)\n",
    "print(\"setGPU.ids\",setGPU.ids)\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    GPU_LIST=[]\n",
    "    list_file_gpu=[]\n",
    "    import os\n",
    "    #os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\n",
    "    with tf.device('/cpu'):\n",
    "        print(\"Start Time CPU\",time.time(), time.clock())\n",
    "        start = timeit.default_timer()\n",
    "        GPU_LIST=get_available_gpus()\n",
    "        list_file_gpu=chunkIt(a,len(GPU_LIST))\n",
    "        print(list_file_gpu)\n",
    "        for i in range(len(GPU_LIST)):\n",
    "            with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=i)):\n",
    "                start_time=time.time()\n",
    "                start_oclock=time.clock()\n",
    "                print(\"Start Time GPU\",i,\"Time is \",start_time,start_oclock)\n",
    "                #gpu_full_process(file_names,path_data_base,path_tf,path_non_redundant,path_idf,file_path_sim)\n",
    "                #Your statements here\n",
    "                print(\"In GPU Dev\",i)\n",
    "                model(list_file_gpu[i],i)\n",
    "                end_time=time.time()\n",
    "                end_oclock=time.clock()\n",
    "                print(\"End Time GPU\",i,\"Time is \",end_time,end_oclock)\n",
    "                total_time_GPU=end_time-start_time\n",
    "                total_clock_GPU=end_oclock-start_oclock\n",
    "                print(\"total_time_GPU\",total_time_GPU)\n",
    "                print(\"total_clock_GPU\",total_clock_GPU)\n",
    "        stop = timeit.default_timer()\n",
    "        print(\"End Time\",time.time(), time.clock())\n",
    "        GPU.showUtilization(all=True)#https://github.com/anderskm/gputil\n",
    "        tl = timeline.Timeline(run_metadata.step_stats)\n",
    "        print(tl.generate_chrome_trace_format(show_memory=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['nvidia-settings', '-t', '-q', 'fsg-Satellite-P750:0[gpu:0]/GPUUtilization']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-70e4de76ea85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mGPU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgethostname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\":0[gpu:0]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'nvidia-settings'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-q'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/GPUUtilization'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mgpu_util\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mgpu_util\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgpu_util\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mcmd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/UsedDedicatedGPUMemory'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0;32m--> 336\u001b[0;31m                **kwargs).stdout\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             raise CalledProcessError(retcode, process.args,\n\u001b[0;32m--> 418\u001b[0;31m                                      output=stdout, stderr=stderr)\n\u001b[0m\u001b[1;32m    419\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['nvidia-settings', '-t', '-q', 'fsg-Satellite-P750:0[gpu:0]/GPUUtilization']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "import json, socket, subprocess, sys, time\n",
    "try:\n",
    "    delay = int(sys.argv[1])\n",
    "except:\n",
    "    delay = 1\n",
    "\n",
    "try:\n",
    "    count = int(sys.argv[2])\n",
    "except:\n",
    "    count = None\n",
    "\n",
    "i = 0\n",
    "while True:\n",
    "    GPU = socket.gethostname() + \":0[gpu:0]\"\n",
    "    print('GPU',GPU)\n",
    "    cmd = ['nvidia-settings', '-t', '-q', GPU + '/GPUUtilization']\n",
    "    print('cmd',cmd)\n",
    "    gpu_util = subprocess.check_output(cmd).strip().split(\",\")\n",
    "    print(\"gpu_util\",gpu_util)\n",
    "    gpu_util = dict([f.strip().split(\"=\") for f in gpu_util])\n",
    "    print(\"gpu_util\",gpu_util)\n",
    "    cmd[-1] = GPU + '/UsedDedicatedGPUMemory'\n",
    "    print(\"cmd[-1]\",cmd[-1])\n",
    "    gpu_used_mem = subprocess.check_output(cmd).strip()\n",
    "    print(\"gpu_used_mem\",gpu_used_mem)\n",
    "    print (\"json\",json.dumps({\"used_mem\": gpu_used_mem, \"util\": gpu_util, \"time\": int(time.time())}))\n",
    "    if count != None:\n",
    "        i += 1\n",
    "        if i == count:\n",
    "            exit(0)\n",
    "            time.sleep(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "2017-12-05 16:20:28.629512: I tensorflow/core/framework/log_memory.cc:35] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocator_name: \"cpu\" }",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b17f388d39cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmemory_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_stderr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmemory_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_memory_timeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_less_than_bytes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/memory_util.py\u001b[0m in \u001b[0;36mprint_memory_timeline\u001b[0;34m(log, gpu_only, ignore_less_than_bytes)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mtotal_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mrecord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemory_timeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallocated_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallocator_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mallocated_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallocated_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memory_util.py\u001b[0m in \u001b[0;36mmemory_timeline\u001b[0;34m(log)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'LOG_MEMORY'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# and not 'step_id: -6' in l:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mparsed_lines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_parse_logline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mallocation_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m# map of <allocation_id>-<allocator_name>->parsed_logline of allocation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memory_util.py\u001b[0m in \u001b[0;36m_parse_logline\u001b[0;34m(l)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m'MemoryLogTensorDeallocation'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_deallocation_regex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"MemoryLogTensorDeallocation\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 2017-12-05 16:20:28.629512: I tensorflow/core/framework/log_memory.cc:35] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocator_name: \"cpu\" }"
     ]
    }
   ],
   "source": [
    "# install memory util\n",
    "import urllib.request\n",
    "response = urllib.request.urlopen(\"https://raw.githubusercontent.com/yaroslavvb/memory_util/master/memory_util.py\")\n",
    "open(\"memory_util.py\", \"wb\").write(response.read())\n",
    "\n",
    "import memory_util\n",
    "memory_util.vlog(1)\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session()\n",
    "a = tf.random_uniform((1000,))\n",
    "b = tf.random_uniform((1000,))\n",
    "c = a + b\n",
    "with memory_util.capture_stderr() as stderr:\n",
    "    sess.run(c.op)\n",
    "memory_util.print_memory_timeline(stderr, ignore_less_than_bytes=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "cmd = 'nvprof --query-metrics'\n",
    "\n",
    "print(os.system(cmd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "/home/fsg/memory_probe_ops.so: undefined symbol: _ZTIN10tensorflow8OpKernelE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b7b26dced2bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mmemory_probe_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_op_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Memory usage: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/load_library.py\u001b[0m in \u001b[0;36mload_op_library\u001b[0;34m(library_filename)\u001b[0m\n\u001b[1;32m     54\u001b[0m   \"\"\"\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mlib_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_LoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibrary_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0mop_list_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetOpList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /home/fsg/memory_probe_ops.so: undefined symbol: _ZTIN10tensorflow8OpKernelE"
     ]
    }
   ],
   "source": [
    "# install memory_probe_ops\n",
    "\n",
    "import urllib.request\n",
    "import sys\n",
    "#sys.path\n",
    "#sys.path.append('./home/fsg/memory_probe_ops.so')\n",
    "\n",
    "path = '/home/fsg/memory_probe_ops.so'\n",
    "#os.environ['PATH'] += ':'+path\n",
    "#print(os.environ)\n",
    "#response = urllib.request.urlopen(\"https://github.com/yaroslavvb/memory_probe_ops/raw/master/linux.memory_probe_ops.so\")\n",
    "#open(\"memory_probe_ops.so\", \"wb\").write(response.read())\n",
    "\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "my_file = Path(path)\n",
    "if my_file.exists():\n",
    "    print(\"yes\")\n",
    "    \n",
    "memory_probe_ops = tf.load_op_library(path)\n",
    "print(\"Memory usage: \")\n",
    "sess = tf.Session()\n",
    "print(sess.run(memory_probe_ops.bytes_in_use()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "2017-12-05 19:47:42.419361: I tensorflow/core/framework/log_memory.cc:35] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocator_name: \"cpu\" }",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-b17f388d39cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmemory_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_stderr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmemory_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_memory_timeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_less_than_bytes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/memory_util.py\u001b[0m in \u001b[0;36mprint_memory_timeline\u001b[0;34m(log, gpu_only, ignore_less_than_bytes)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mtotal_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mrecord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemory_timeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallocated_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallocator_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mallocated_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallocated_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memory_util.py\u001b[0m in \u001b[0;36mmemory_timeline\u001b[0;34m(log)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'LOG_MEMORY'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# and not 'step_id: -6' in l:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mparsed_lines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_parse_logline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mallocation_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m# map of <allocation_id>-<allocator_name>->parsed_logline of allocation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memory_util.py\u001b[0m in \u001b[0;36m_parse_logline\u001b[0;34m(l)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m'MemoryLogTensorDeallocation'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_deallocation_regex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"MemoryLogTensorDeallocation\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 2017-12-05 19:47:42.419361: I tensorflow/core/framework/log_memory.cc:35] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocator_name: \"cpu\" }"
     ]
    }
   ],
   "source": [
    "# install memory util\n",
    "import urllib.request\n",
    "response = urllib.request.urlopen(\"https://raw.githubusercontent.com/yaroslavvb/memory_util/master/memory_util.py\")\n",
    "open(\"memory_util.py\", \"wb\").write(response.read())\n",
    "\n",
    "import memory_util\n",
    "memory_util.vlog(1)\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session()\n",
    "a = tf.random_uniform((1000,))\n",
    "b = tf.random_uniform((1000,))\n",
    "c = a + b\n",
    "with memory_util.capture_stderr() as stderr:\n",
    "    sess.run(c.op)\n",
    "memory_util.print_memory_timeline(stderr, ignore_less_than_bytes=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ./memory_probe_ops.so\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "./memory_probe_ops.so: undefined symbol: _ZTIN10tensorflow8OpKernelE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-6adb5a66c753>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_so_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_so_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mmemory_probe_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_op_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_so_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/load_library.py\u001b[0m in \u001b[0;36mload_op_library\u001b[0;34m(library_filename)\u001b[0m\n\u001b[1;32m     54\u001b[0m   \"\"\"\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mlib_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_LoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibrary_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0mop_list_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetOpList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: ./memory_probe_ops.so: undefined symbol: _ZTIN10tensorflow8OpKernelE"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "so_name = \"memory_probe_ops.so\"\n",
    "\n",
    "paths_to_search = []\n",
    "paths_to_search.append('.')\n",
    "for path in paths_to_search:\n",
    "    full_so_name = os.path.join(path, so_name)\n",
    "    if os.path.exists(full_so_name):\n",
    "        print(\"Loading %s\" %(full_so_name))\n",
    "        memory_probe_ops = tf.load_op_library(full_so_name)\n",
    "        break\n",
    "else:\n",
    "    print(\"Unable to find %s in %s, quitting\"%(so_name, paths_to_search,))\n",
    "    sys.exit()\n",
    "    \n",
    "run_with_tracing = False\n",
    "config = tf.ConfigProto()\n",
    "#config = tf.ConfigProto(graph_options=tf.GraphOptions(optimizer_options=tf.OptimizerOptions(opt_level=tf.OptimizerOptions.L0)))\n",
    "\n",
    "for d in [\"/cpu:0\", \"/gpu:0\"]:\n",
    "    with tf.device(d):\n",
    "        sess = tf.InteractiveSession(config=config)\n",
    "        mbs = 12\n",
    "        n = mbs*250000\n",
    "        inputs = tf.random_uniform((n,))\n",
    "        print(\"Allocating %d MB variable on %s\"%(mbs, d,))\n",
    "        var = tf.Variable(inputs)\n",
    "        probe_op = memory_probe_ops.bytes_in_use()\n",
    "        max_op = memory_probe_ops.bytes_limit()\n",
    "        name_op = memory_probe_ops.allocator_name()\n",
    "        run_metadata = tf.RunMetadata()\n",
    "        run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "        print(\"Before init %10d out of %10d bytes with allocator %s\" % tuple(sess.run([probe_op, max_op, name_op])))\n",
    "        sess.run(var.initializer)\n",
    "        print(\"After  init %10d out of %10d bytes with allocator %s\" % tuple(sess.run([probe_op, max_op, name_op])))\n",
    "        if run_with_tracing:\n",
    "            print(run_metadata)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess, re, os, sys\n",
    "def run_command(cmd):\n",
    "    \"\"\"Run command, return output as string.\"\"\"\n",
    "    \n",
    "    output = subprocess.Popen(cmd, stdout=subprocess.PIPE, shell=True).communicate()[0]\n",
    "    return output.decode(\"ascii\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def list_available_gpus():\n",
    "    \"\"\"Returns list of available GPU ids.\"\"\"\n",
    "    \n",
    "    output = run_command(\"nvidia-smi -L\")\n",
    "    # lines of the form GPU 0: TITAN X\n",
    "    gpu_regex = re.compile(r\"GPU (?P<gpu_id>\\d+):\")\n",
    "    result = []\n",
    "    for line in output.strip().split(\"\\n\"):\n",
    "        m = gpu_regex.match(line)\n",
    "        assert m, \"Couldnt parse \"+line\n",
    "        result.append(int(m.group(\"gpu_id\")))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gpu_memory_map():\n",
    "    \"\"\"Returns map of GPU id to memory allocated on that GPU.\"\"\"\n",
    "\n",
    "    output = run_command(\"nvidia-smi\")\n",
    "    gpu_output = output[output.find(\"GPU Memory\"):]\n",
    "    # lines of the form\n",
    "    # |    0      8734    C   python                                       11705MiB |\n",
    "    memory_regex = re.compile(r\"[|]\\s+?(?P<gpu_id>\\d+)\\D+?(?P<pid>\\d+).+[ ](?P<gpu_memory>\\d+)MiB\")\n",
    "    rows = gpu_output.split(\"\\n\")\n",
    "    result = {gpu_id: 0 for gpu_id in list_available_gpus()}\n",
    "    for row in gpu_output.split(\"\\n\"):\n",
    "        m = memory_regex.search(row)\n",
    "        if not m:\n",
    "            continue\n",
    "        gpu_id = int(m.group(\"gpu_id\"))\n",
    "        gpu_memory = int(m.group(\"gpu_memory\"))\n",
    "        result[gpu_id] += gpu_memory\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_memory_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
