{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_parallel in_splits {'a': [<tf.Tensor 'split:0' shape=(200, 100) dtype=float32>, <tf.Tensor 'split:1' shape=(200, 100) dtype=float32>, <tf.Tensor 'split:2' shape=(200, 100) dtype=float32>, <tf.Tensor 'split:3' shape=(200, 100) dtype=float32>, <tf.Tensor 'split:4' shape=(200, 100) dtype=float32>], 'b': [<tf.Tensor 'split_1:0' shape=(200, 100) dtype=float32>, <tf.Tensor 'split_1:1' shape=(200, 100) dtype=float32>, <tf.Tensor 'split_1:2' shape=(200, 100) dtype=float32>, <tf.Tensor 'split_1:3' shape=(200, 100) dtype=float32>, <tf.Tensor 'split_1:4' shape=(200, 100) dtype=float32>]}\n",
      "0\n",
      "fff {'a': <tf.Tensor 'split:0' shape=(200, 100) dtype=float32>, 'b': <tf.Tensor 'split_1:0' shape=(200, 100) dtype=float32>}\n",
      "In Model GPU A:  Tensor(\"split:0\", shape=(200, 100), dtype=float32)\n",
      "In Model GPU B:  Tensor(\"split_1:0\", shape=(200, 100), dtype=float32)\n",
      "1\n",
      "fff {'a': <tf.Tensor 'split:1' shape=(200, 100) dtype=float32>, 'b': <tf.Tensor 'split_1:1' shape=(200, 100) dtype=float32>}\n",
      "In Model GPU A:  Tensor(\"split:1\", shape=(200, 100), dtype=float32)\n",
      "In Model GPU B:  Tensor(\"split_1:1\", shape=(200, 100), dtype=float32)\n",
      "2\n",
      "fff {'a': <tf.Tensor 'split:2' shape=(200, 100) dtype=float32>, 'b': <tf.Tensor 'split_1:2' shape=(200, 100) dtype=float32>}\n",
      "In Model GPU A:  Tensor(\"split:2\", shape=(200, 100), dtype=float32)\n",
      "In Model GPU B:  Tensor(\"split_1:2\", shape=(200, 100), dtype=float32)\n",
      "3\n",
      "fff {'a': <tf.Tensor 'split:3' shape=(200, 100) dtype=float32>, 'b': <tf.Tensor 'split_1:3' shape=(200, 100) dtype=float32>}\n",
      "In Model GPU A:  Tensor(\"split:3\", shape=(200, 100), dtype=float32)\n",
      "In Model GPU B:  Tensor(\"split_1:3\", shape=(200, 100), dtype=float32)\n",
      "4\n",
      "fff {'a': <tf.Tensor 'split:4' shape=(200, 100) dtype=float32>, 'b': <tf.Tensor 'split_1:4' shape=(200, 100) dtype=float32>}\n",
      "In Model GPU A:  Tensor(\"split:4\", shape=(200, 100), dtype=float32)\n",
      "In Model GPU B:  Tensor(\"split_1:4\", shape=(200, 100), dtype=float32)\n",
      "make_parallel out_split [<tf.Tensor 'add:0' shape=(200, 100) dtype=float32>, <tf.Tensor 'add_1:0' shape=(200, 100) dtype=float32>, <tf.Tensor 'add_2:0' shape=(200, 100) dtype=float32>, <tf.Tensor 'add_3:0' shape=(200, 100) dtype=float32>, <tf.Tensor 'add_4:0' shape=(200, 100) dtype=float32>]\n",
      "Start Time 1512378670.0223846 16.295481\n",
      "End Time 1512378670.0246453 16.300463\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    #a=[\"A\",\"B\",\"C\",\"D\"]\n",
    "    #b=[\"1\",\"2\",\"3\",\"4\"]\n",
    "    a = tf.random_uniform([1000, 100])\n",
    "    b = tf.random_uniform([1000, 100])\n",
    "    def model(a,b):\n",
    "        #print(\"In Model GPU: \",i)\n",
    "        print(\"In Model GPU A: \",a)\n",
    "        print(\"In Model GPU B: \",b)\n",
    "        c=a+b\n",
    "        return c#a+b #\"In GPU:\"#+str(a)+\" \"+str(b)#+str(i)\n",
    "\n",
    "    \n",
    "    def make_parallel(fn, num_gpus, **kwargs):\n",
    "\n",
    "\n",
    "        in_splits = {}\n",
    "        for k, v in kwargs.items():\n",
    "            in_splits[k] = tf.split(v, num_gpus)\n",
    "        print(\"make_parallel in_splits\", in_splits)\n",
    "        out_split = []\n",
    "        for i in range(num_gpus):\n",
    "            print(i)\n",
    "            #with tf.device(tf.DeviceSpec(device_type=\"CPU\", device_index=i)):\n",
    "                #with tf.variable_scope(tf.get_variable_scope(), reuse=i > 0):\n",
    "            print(\"fff\",{k : v[i] for k, v in in_splits.items()})\n",
    "            out_split.append(fn(**{k : v[i] for k, v in in_splits.items()}))\n",
    "        print(\"make_parallel out_split\",out_split)\n",
    "        return tf.concat(out_split, axis=0)\n",
    "    c = make_parallel(model, 5, a=a, b=b)\n",
    "    tf.summary.FileWriter(\"/home/fsg/logs_tf\", g).close()\n",
    "\n",
    "\n",
    "#with tf.device(tf.DeviceSpec(device_type=\"CPU\", device_index=0)):\n",
    "#a = tf.random_uniform([1000, 100])\n",
    "#b = tf.random_uniform([1000, 100])\n",
    "    #c = a + b\n",
    "\n",
    "\n",
    "\n",
    "config = tf.ConfigProto(device_count={\"GPU\": 2,\"CPU\":1},\n",
    "                        allow_soft_placement=True,\n",
    "                        inter_op_parallelism_threads=16,\n",
    "                        intra_op_parallelism_threads=16,\n",
    "                        use_per_session_threads=True,\n",
    "                        log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "print(\"Start Time\",time.time(), time.clock())\n",
    "\n",
    "sess = tf.Session(config=config,graph=g)\n",
    "#sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#print(\"C\",sess.run(c))\n",
    "#tf.summary.FileWriter(\"/home/fsg/logs_tf\", g).close()\n",
    "\n",
    "\n",
    "print(\"End Time\",time.time(), time.clock())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
