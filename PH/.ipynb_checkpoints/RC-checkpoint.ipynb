{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv   \n",
    "def add_row(row,path_database,file_name):\n",
    "    #fields=['first','second','third']\n",
    "    with open(path_database+file_name, 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(row)\n",
    "        print(\"printed\")\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printed\n"
     ]
    }
   ],
   "source": [
    "header_list=['index','text']\n",
    "add_row(header_list,'./',\"R_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters \n",
    " \n",
    "def collection_stats():\n",
    "    # List of documents\n",
    "    documents = reuters.fileids()\n",
    "    #print(str(len(documents)) + \" documents\");\n",
    " \n",
    "    #train_docs = list(filter(lambda doc: doc.startswith(\"train\"),documents));\n",
    "    #print(str(len(train_docs)) + \" total train documents\");\n",
    " \n",
    "    #test_docs = list(filter(lambda doc: doc.startswith(\"test\"),documents));\n",
    "    #print(str(len(test_docs)) + \" total test documents\");\n",
    " \n",
    "    # List of categories\n",
    "    categories = reuters.categories();\n",
    "    #print(str(len(categories)) + \" categories\");\n",
    "    index=0\n",
    "    paragraph_list=[]\n",
    "    for i in range (1):#len(categories)):\n",
    "        category_docs = reuters.fileids(categories[i]);\n",
    "        for x in range (2):#len(category_docs)):\n",
    "            row=[]\n",
    "            document_id = category_docs[x]\n",
    "            row.append(index)\n",
    "            doc=reuters.raw(document_id)\n",
    "            row.append(doc)\n",
    "            add_row(row,'./',\"R_text.csv\")\n",
    "            index =+1\n",
    "            \n",
    "            \n",
    "        \n",
    " \n",
    "    # Documents in a category\n",
    "    #category_docs = reuters.fileids(\"acq\");\n",
    " \n",
    "    # Words for a document\n",
    "    #document_id = category_docs[0]\n",
    "    #document_words = reuters.words(category_docs[0]);\n",
    "    #print(document_words);  \n",
    " \n",
    "    # Raw document\n",
    "    #print(reuters.raw(document_id));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters \n",
    "def collection_stats():\n",
    "    # List of documents\n",
    "    documents = reuters.fileids()\n",
    "   \n",
    "    categories = reuters.categories();\n",
    "    index=0\n",
    "    category_docs = reuters.fileids('crude');\n",
    "    for x in range (2):#len(category_docs)):\n",
    "            row=[]\n",
    "            document_id = category_docs[x]\n",
    "            row.append(index)\n",
    "            doc=reuters.raw(document_id)\n",
    "            row.append(doc)\n",
    "            add_row(row,'./',\"R_text.csv\")\n",
    "            index =+1\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crude 578\n",
      "['JAPAN', 'TO', 'REVISE', 'LONG', '-', 'TERM', ...]\n",
      "JAPAN TO REVISE LONG-TERM ENERGY DEMAND DOWNWARDS\n",
      "  The Ministry of International Trade and\n",
      "  Industry (MITI) will revise its long-term energy supply/demand\n",
      "  outlook by August to meet a forecast downtrend in Japanese\n",
      "  energy demand, ministry officials said.\n",
      "      MITI is expected to lower the projection for primary energy\n",
      "  supplies in the year 2000 to 550 mln kilolitres (kl) from 600\n",
      "  mln, they said.\n",
      "      The decision follows the emergence of structural changes in\n",
      "  Japanese industry following the rise in the value of the yen\n",
      "  and a decline in domestic electric power demand.\n",
      "      MITI is planning to work out a revised energy supply/demand\n",
      "  outlook through deliberations of committee meetings of the\n",
      "  Agency of Natural Resources and Energy, the officials said.\n",
      "      They said MITI will also review the breakdown of energy\n",
      "  supply sources, including oil, nuclear, coal and natural gas.\n",
      "      Nuclear energy provided the bulk of Japan's electric power\n",
      "  in the fiscal year ended March 31, supplying an estimated 27\n",
      "  pct on a kilowatt/hour basis, followed by oil (23 pct) and\n",
      "  liquefied natural gas (21 pct), they noted.\n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "collection_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test/14826'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = reuters.fileids()\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn', 'cotton', 'cotton-oil', 'cpi', 'cpu', 'crude', 'dfl', 'dlr', 'dmk', 'earn', 'fuel', 'gas', 'gnp', 'gold', 'grain', 'groundnut', 'groundnut-oil', 'heat', 'hog', 'housing', 'income', 'instal-debt', 'interest', 'ipi', 'iron-steel', 'jet', 'jobs', 'l-cattle', 'lead', 'lei', 'lin-oil', 'livestock', 'lumber', 'meal-feed', 'money-fx', 'money-supply', 'naphtha', 'nat-gas', 'nickel', 'nkr', 'nzdlr', 'oat', 'oilseed', 'orange', 'palladium', 'palm-oil', 'palmkernel', 'pet-chem', 'platinum', 'potato', 'propane', 'rand', 'rape-oil', 'rapeseed', 'reserves', 'retail', 'rice', 'rubber', 'rye', 'ship', 'silver', 'sorghum', 'soy-meal', 'soy-oil', 'soybean', 'strategic-metal', 'sugar', 'sun-meal', 'sun-oil', 'sunseed', 'tea', 'tin', 'trade', 'veg-oil', 'wheat', 'wpi', 'yen', 'zinc']\n"
     ]
    }
   ],
   "source": [
    "categories = reuters.categories();\n",
    "print(categories );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "category_docs = reuters.fileids(\"cpu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test/21245'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_docs\n",
    " # Words for a document\n",
    "document_id = category_docs[0]\n",
    "document_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://chrisstrelioff.ws/sandbox/2014/11/13/getting_started_with_latent_dirichlet_allocation_in_python.html\n",
    "from __future__ import division, print_function\n",
    "\n",
    "import numpy as np\n",
    "import lda\n",
    "import lda.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(X): <class 'numpy.ndarray'>\n",
      "shape: (395, 4258)\n",
      "\n",
      "type(vocab): <class 'tuple'>\n",
      "len(vocab): 4258\n",
      "\n",
      "type(titles): <class 'tuple'>\n",
      "len(titles): 395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# document-term matrix\n",
    "X = lda.datasets.load_reuters()\n",
    "print(\"type(X): {}\".format(type(X)))\n",
    "print(\"shape: {}\\n\".format(X.shape))\n",
    "\n",
    "# the vocab\n",
    "vocab = lda.datasets.load_reuters_vocab()\n",
    "print(\"type(vocab): {}\".format(type(vocab)))\n",
    "print(\"len(vocab): {}\\n\".format(len(vocab)))\n",
    "\n",
    "# titles for each story\n",
    "titles = lda.datasets.load_reuters_titles()\n",
    "print(\"type(titles): {}\".format(type(titles)))\n",
    "print(\"len(titles): {}\\n\".format(len(titles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 GERMANY: Historic Dresden church rising from WW2 ashes. DRESDEN, Germany 1996-08-21'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc id: 0 word id: 3117\n",
      "-- count: 2\n",
      "-- word : heir-to-the-throne\n",
      "-- doc  : 0 UK: Prince Charles spearheads British royal revolution. LONDON 1996-08-20\n"
     ]
    }
   ],
   "source": [
    "doc_id = 0\n",
    "word_id = 3117\n",
    "\n",
    "print(\"doc id: {} word id: {}\".format(doc_id, word_id))\n",
    "print(\"-- count: {}\".format(X[doc_id, word_id]))\n",
    "print(\"-- word : {}\".format(vocab[word_id]))\n",
    "print(\"-- doc  : {}\".format(titles[doc_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 395\n",
      "INFO:lda:vocab_size: 4258\n",
      "INFO:lda:n_words: 84010\n",
      "INFO:lda:n_topics: 400\n",
      "INFO:lda:n_iter: 500\n",
      "INFO:lda:<0> log likelihood: -1377619\n",
      "INFO:lda:<10> log likelihood: -783814\n",
      "INFO:lda:<20> log likelihood: -756614\n",
      "INFO:lda:<30> log likelihood: -748178\n",
      "INFO:lda:<40> log likelihood: -744013\n",
      "INFO:lda:<50> log likelihood: -740222\n",
      "INFO:lda:<60> log likelihood: -739453\n",
      "INFO:lda:<70> log likelihood: -736763\n",
      "INFO:lda:<80> log likelihood: -735908\n",
      "INFO:lda:<90> log likelihood: -736475\n",
      "INFO:lda:<100> log likelihood: -734748\n",
      "INFO:lda:<110> log likelihood: -733912\n",
      "INFO:lda:<120> log likelihood: -731744\n",
      "INFO:lda:<130> log likelihood: -732981\n",
      "INFO:lda:<140> log likelihood: -732141\n",
      "INFO:lda:<150> log likelihood: -731041\n",
      "INFO:lda:<160> log likelihood: -731605\n",
      "INFO:lda:<170> log likelihood: -730907\n",
      "INFO:lda:<180> log likelihood: -730013\n",
      "INFO:lda:<190> log likelihood: -729697\n",
      "INFO:lda:<200> log likelihood: -729842\n",
      "INFO:lda:<210> log likelihood: -729959\n",
      "INFO:lda:<220> log likelihood: -728964\n",
      "INFO:lda:<230> log likelihood: -729001\n",
      "INFO:lda:<240> log likelihood: -729680\n",
      "INFO:lda:<250> log likelihood: -729611\n",
      "INFO:lda:<260> log likelihood: -729167\n",
      "INFO:lda:<270> log likelihood: -727949\n",
      "INFO:lda:<280> log likelihood: -729393\n",
      "INFO:lda:<290> log likelihood: -728290\n",
      "INFO:lda:<300> log likelihood: -727798\n",
      "INFO:lda:<310> log likelihood: -727579\n",
      "INFO:lda:<320> log likelihood: -728113\n",
      "INFO:lda:<330> log likelihood: -728147\n",
      "INFO:lda:<340> log likelihood: -729081\n",
      "INFO:lda:<350> log likelihood: -727709\n",
      "INFO:lda:<360> log likelihood: -727419\n",
      "INFO:lda:<370> log likelihood: -727568\n",
      "INFO:lda:<380> log likelihood: -729112\n",
      "INFO:lda:<390> log likelihood: -729125\n",
      "INFO:lda:<400> log likelihood: -728012\n",
      "INFO:lda:<410> log likelihood: -728265\n",
      "INFO:lda:<420> log likelihood: -728620\n",
      "INFO:lda:<430> log likelihood: -727775\n",
      "INFO:lda:<440> log likelihood: -728192\n",
      "INFO:lda:<450> log likelihood: -727700\n",
      "INFO:lda:<460> log likelihood: -727223\n",
      "INFO:lda:<470> log likelihood: -727552\n",
      "INFO:lda:<480> log likelihood: -726679\n",
      "INFO:lda:<490> log likelihood: -728748\n",
      "INFO:lda:<499> log likelihood: -728433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lda.lda.LDA at 0x7fc41c50be10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lda.LDA(n_topics=400, n_iter=500, random_state=1)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://www.machinelearningplus.com/nlp/topic-modeling-python-sklearn-examples/\n",
    "# Run in terminal or command prompt\n",
    "# python3 -m spacy download en\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, nltk, spacy, gensim\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rec.autos' 'comp.sys.mac.hardware' 'rec.motorcycles' 'misc.forsale'\n",
      " 'comp.os.ms-windows.misc' 'alt.atheism' 'comp.graphics'\n",
      " 'rec.sport.baseball' 'rec.sport.hockey' 'sci.electronics' 'sci.space'\n",
      " 'talk.politics.misc' 'sci.med' 'talk.politics.mideast'\n",
      " 'soc.religion.christian' 'comp.windows.x' 'comp.sys.ibm.pc.hardware'\n",
      " 'talk.politics.guns' 'talk.religion.misc' 'sci.crypt']\n"
     ]
    }
   ],
   "source": [
    "# Import Dataset\n",
    "df = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
    "print(df.target_names.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>From: irwin@cmptrc.lonestar.org (Irwin Arnstei...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>From: tchen@magnus.acs.ohio-state.edu (Tsung-K...</td>\n",
       "      <td>6</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>From: dabl2@nlm.nih.gov (Don A.B. Lindbergh)\\n...</td>\n",
       "      <td>2</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>From: a207706@moe.dseg.ti.com (Robert Loper)\\n...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>From: kimman@magnus.acs.ohio-state.edu (Kim Ri...</td>\n",
       "      <td>6</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>From: kwilson@casbah.acns.nwu.edu (Kirtley Wil...</td>\n",
       "      <td>2</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>Subject: Re: Don't more innocents die without ...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>From: livesey@solntze.wpd.sgi.com (Jon Livesey...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005</th>\n",
       "      <td>From: dls@aeg.dsto.gov.au (David Silver)\\nSubj...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10006</th>\n",
       "      <td>Subject: Re: Mike Francesa's 1993 Predictions\\...</td>\n",
       "      <td>9</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10007</th>\n",
       "      <td>From: jet@netcom.Netcom.COM (J. Eric Townsend)...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10008</th>\n",
       "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10009</th>\n",
       "      <td>From: sehari@iastate.edu (Babak Sehari)\\nSubje...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  target  \\\n",
       "0      From: lerxst@wam.umd.edu (where's my thing)\\nS...       7   \n",
       "1      From: guykuo@carson.u.washington.edu (Guy Kuo)...       4   \n",
       "10     From: irwin@cmptrc.lonestar.org (Irwin Arnstei...       8   \n",
       "100    From: tchen@magnus.acs.ohio-state.edu (Tsung-K...       6   \n",
       "1000   From: dabl2@nlm.nih.gov (Don A.B. Lindbergh)\\n...       2   \n",
       "10000  From: a207706@moe.dseg.ti.com (Robert Loper)\\n...       7   \n",
       "10001  From: kimman@magnus.acs.ohio-state.edu (Kim Ri...       6   \n",
       "10002  From: kwilson@casbah.acns.nwu.edu (Kirtley Wil...       2   \n",
       "10003  Subject: Re: Don't more innocents die without ...       0   \n",
       "10004  From: livesey@solntze.wpd.sgi.com (Jon Livesey...       0   \n",
       "10005  From: dls@aeg.dsto.gov.au (David Silver)\\nSubj...       1   \n",
       "10006  Subject: Re: Mike Francesa's 1993 Predictions\\...       9   \n",
       "10007  From: jet@netcom.Netcom.COM (J. Eric Townsend)...       8   \n",
       "10008  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...      10   \n",
       "10009  From: sehari@iastate.edu (Babak Sehari)\\nSubje...      12   \n",
       "\n",
       "                  target_names  \n",
       "0                    rec.autos  \n",
       "1        comp.sys.mac.hardware  \n",
       "10             rec.motorcycles  \n",
       "100               misc.forsale  \n",
       "1000   comp.os.ms-windows.misc  \n",
       "10000                rec.autos  \n",
       "10001             misc.forsale  \n",
       "10002  comp.os.ms-windows.misc  \n",
       "10003              alt.atheism  \n",
       "10004              alt.atheism  \n",
       "10005            comp.graphics  \n",
       "10006       rec.sport.baseball  \n",
       "10007          rec.motorcycles  \n",
       "10008         rec.sport.hockey  \n",
       "10009          sci.electronics  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<input>:5: DeprecationWarning: invalid escape sequence \\S\n",
      "<input>:8: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:5: DeprecationWarning: invalid escape sequence \\S\n",
      "<input>:8: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:5: DeprecationWarning: invalid escape sequence \\S\n",
      "<input>:8: DeprecationWarning: invalid escape sequence \\s\n",
      "<ipython-input-4-10af9153bd18>:5: DeprecationWarning: invalid escape sequence \\S\n",
      "  data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
      "<ipython-input-4-10af9153bd18>:8: DeprecationWarning: invalid escape sequence \\s\n",
      "  data = [re.sub('\\s+', ' ', sent) for sent in data]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From: (wheres my thing) Subject: WHAT car is this!? Nntp-Posting-Host: '\n",
      " 'rac3.wam.umd.edu Organization: University of Maryland, College Park Lines: '\n",
      " '15 I was wondering if anyone out there could enlighten me on this car I saw '\n",
      " 'the other day. It was a 2-door sports car, looked to be from the late 60s/ '\n",
      " 'early 70s. It was called a Bricklin. The doors were really small. In '\n",
      " 'addition, the front bumper was separate from the rest of the body. This is '\n",
      " 'all I know. If anyone can tellme a model name, engine specs, years of '\n",
      " 'production, where this car is made, history, or whatever info you have on '\n",
      " 'this funky looking car, please e-mail. Thanks, - IL ---- brought to you by '\n",
      " 'your neighborhood Lerxst ---- ']\n"
     ]
    }
   ],
   "source": [
    "# Convert to list\n",
    "data = df.content.values.tolist()\n",
    "\n",
    "# Remove Emails\n",
    "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
    "\n",
    "# Remove new line characters\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "pprint(data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp', 'posting', 'host', 'rac', 'wam', 'umd', 'edu', 'organization', 'university', 'of', 'maryland', 'college', 'park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:88: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr))[0]\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:88: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr))[0]\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:88: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr))[0]\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:88: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr))[0]\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:88: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr))[0]\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:88: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr))[0]\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:88: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr))[0]\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:88: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr))[0]\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:88: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr))[0]\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:88: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr))[0]\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:88: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr))[0]\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n",
      "/home/fsg/.local/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n"
     ]
    }
   ],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append(\" \".join([token.lemma_ if token.lemma_ not in ['-PRON-'] else '' for token in doc if token.pos_ in allowed_postags]))\n",
    "    return texts_out\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# Run in terminal: python3 -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only Noun, Adj, Verb, Adverb\n",
    "data_lemmatized = lemmatization(data_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word',       \n",
    "                             min_df=10,                        # minimum reqd occurences of a word \n",
    "                             stop_words='english',             # remove stop words\n",
    "                             lowercase=True,                   # convert all words to lowercase\n",
    "                             token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n",
    "                             # max_features=50000,             # max number of uniq words\n",
    "                            )\n",
    "\n",
    "data_vectorized = vectorizer.fit_transform(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Materialize the sparse data\n",
    "data_dense = data_vectorized.todense()\n",
    "\n",
    "# Compute Sparsicity = Percentage of Non-Zero cells\n",
    "print(\"Sparsicity: \", ((data_dense > 0).sum()/data_dense.size)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build LDA Model\n",
    "lda_model = LatentDirichletAllocation(n_topics=20,               # Number of topics\n",
    "                                      max_iter=10,               # Max learning iterations\n",
    "                                      learning_method='online',   \n",
    "                                      random_state=100,          # Random state\n",
    "                                      batch_size=128,            # n docs in each learning iter\n",
    "                                      evaluate_every = -1,       # compute perplexity every n iters, default: Don't\n",
    "                                      n_jobs = -1,               # Use all available CPUs\n",
    "                                     )\n",
    "lda_output = lda_model.fit_transform(data_vectorized)\n",
    "\n",
    "print(lda_model)  # Model attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
    "             evaluate_every=-1, learning_decay=0.7,\n",
    "             learning_method='online', learning_offset=10.0,\n",
    "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
    "             n_components=10, n_jobs=-1, n_topics=20, perp_tol=0.1,\n",
    "             random_state=100, topic_word_prior=None,\n",
    "             total_samples=1000000.0, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Log Likelyhood: Higher the better\n",
    "print(\"Log Likelihood: \", lda_model.score(data_vectorized))\n",
    "\n",
    "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "print(\"Perplexity: \", lda_model.perplexity(data_vectorized))\n",
    "\n",
    "# See model parameters\n",
    "pprint(lda_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism',\n",
      " 'comp.graphics',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'comp.windows.x',\n",
      " 'misc.forsale',\n",
      " 'rec.autos',\n",
      " 'rec.motorcycles',\n",
      " 'rec.sport.baseball',\n",
      " 'rec.sport.hockey',\n",
      " 'sci.crypt',\n",
      " 'sci.electronics',\n",
      " 'sci.med',\n",
      " 'sci.space',\n",
      " 'soc.religion.christian',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.mideast',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n",
      "(11314,)\n",
      "584\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))#,categories=['comp.graphics'])#fetch_20newsgroups(subset='train')\n",
    "\n",
    "from pprint import pprint\n",
    "cat_list=list(newsgroups_train.target_names)\n",
    "pprint(list(newsgroups_train.target_names))\n",
    "print(newsgroups_train.filenames.shape)\n",
    "#for c in cat_list:\n",
    "sub = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'),categories=['comp.graphics'])#fetch_20newsgroups(subset='train')\n",
    "#print(c,sub.filenames.shape)\n",
    "documents = sub.data\n",
    "print(len(documents))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
