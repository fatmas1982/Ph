{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! /usr/bin/python3.6\n",
    "'''\n",
    "Created on Jul 19, 2016\n",
    "\n",
    "@author: shuangyinli\n",
    "'''\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "\n",
    "import random\n",
    "import time\n",
    "import multiprocessing\n",
    "from multiprocessing import Process,Manager\n",
    "import copy\n",
    "import sys\n",
    "import math\n",
    "\n",
    "\n",
    "def log_sum(log_a, log_b):\n",
    "    if log_a < log_b:\n",
    "        return log_b + log(1+exp(log_a-log_b))\n",
    "    else:\n",
    "        return log_a + log(1+exp(log_b-log_a))\n",
    "def trigamma(x):\n",
    "    x = x + 6\n",
    "    p = 1 / (x * x)\n",
    "    p = (((((0.075757575757576 * p - 0.033333333333333) * p + 0.0238095238095238) * p - 0.033333333333333) * p + 0.166666666666667) * p + 1) / x + 0.5 * p\n",
    "    for i in range(6):\n",
    "        x = x - 1\n",
    "        p = 1 / (x * x) + p\n",
    "    return p\n",
    "def log_gamma(x):\n",
    "    PI = math.acos(-1.0)\n",
    "    tmp = (x - 0.5) * log(x + 4.5) - (x + 4.5)\n",
    "    ser = 1.0 + 76.18009173 / (x + 0) - 86.50532033 / (x + 1) + 24.01409822 / (x + 2) - 1.231739516 / (x + 3) + 0.00120858003 / (x + 4) - 0.00000536382 / (x + 5)\n",
    "    return tmp + log(ser * sqrt(2 * PI))\n",
    "def digamma(x):\n",
    "    r = 0.0\n",
    "    while x <=5:\n",
    "        r -= 1/x\n",
    "        x += 1\n",
    "    f = 1.0 / (x * x)\n",
    "    t = f * (-1.0 / 12.0 + f * (1.0 / 120.0 + f * (-1.0 / 252.0 + f * (1.0 / 240.0 + f * (-1.0 / 132.0 + f * (691.0 / 32760.0 + f * (-1.0 / 12.0 + f * 3617.0 / 8160.0)))))))\n",
    "    return r + log(x) - 0.5 / x + t\n",
    "def norm2(vec1, vec2, dim):\n",
    "    ret =0\n",
    "    for i in range(dim):\n",
    "        ret += (vec1[i] - vec2[i]) * (vec1[i] - vec2[i])\n",
    "    return ret\n",
    "    \n",
    "class Document():\n",
    "    def __init__(self, num_tags_, num_words_, num_topics_, lik_,\n",
    "                tags_ptr_, words_ptr_, words_cnt_ptr_):\n",
    "        '''\n",
    "        Constructor\n",
    "        '''\n",
    "        self.num_tags = num_tags_ # tag num in each doc\n",
    "        self.num_words = num_words_\n",
    "        self.num_topics = num_topics_\n",
    "        self.lik = lik_\n",
    "        self.tags_ptr = tags_ptr_\n",
    "        self.words_ptr = words_ptr_\n",
    "        self.words_cnt_ptr = words_cnt_ptr_\n",
    "        self.xi = [0 for i in range(self.num_tags)]\n",
    "        self.log_gamma = np.ndarray(shape = (self.num_words, self.num_topics), dtype = float)\n",
    "        self.topic = [0 for i in range(self.num_topics)]\n",
    "        self.Document_init()\n",
    "\n",
    "    def Document_init(self):\n",
    "        for i in range(self.num_tags):\n",
    "            self.xi[i] = random.random()+0.5\n",
    "        for i in range(self.num_words):\n",
    "            for k in range(self.num_topics):\n",
    "                self.log_gamma[i][k] = log(1.0 / self.num_topics)\n",
    "        \n",
    "class Model():\n",
    "    def __init__(self, model_root_, num_docs_,num_words_,num_topics_,num_tags_,num_all_words_):\n",
    "        '''\n",
    "        Constructor\n",
    "        '''\n",
    "        self.num_docs = num_docs_\n",
    "        self.num_words=num_words_\n",
    "        self.num_topics=num_topics_\n",
    "        self.num_tags=num_tags_ # all the tags number\n",
    "        self.num_all_words=num_all_words_\n",
    "        self.pi = [0.0 for i in range(self.num_tags)]\n",
    "        self.log_theta=  np.ndarray(shape=(self.num_tags,self.num_topics), dtype=float )\n",
    "        self.log_phi= np.ndarray(shape=(self.num_topics,self.num_words), dtype=float )\n",
    "        self.model_root = model_root_\n",
    "        self.model_init()\n",
    "        \n",
    "    def model_init(self):\n",
    "        for i in range(self.num_tags):\n",
    "            self.pi[i] = random.random() * 0.5 +1\n",
    "            temp = 0.0\n",
    "            for k in range(self.num_topics):\n",
    "                v = random.random()\n",
    "                temp += v\n",
    "                self.log_theta[i][k] = v\n",
    "            for k in range(self.num_topics):\n",
    "                self.log_theta[i][k] = log(self.log_theta[i][k] / temp)\n",
    "        for k in range(self.num_topics):\n",
    "            for w in range(self.num_words):\n",
    "                self.log_phi[k][w] = log(1.0 / self.num_words)\n",
    "    \n",
    "    def read_model_info(self):\n",
    "        pass\n",
    "    \n",
    "    def load_mat(self):\n",
    "        pass\n",
    "    \n",
    "    def save_model(self, num_round):\n",
    "        if num_round != -1:\n",
    "            pi_file = self.model_root+\"pi.\"+str(num_round)\n",
    "            theta_file = self.model_root+\"theta.\"+str(num_round)\n",
    "            phi_file = self.model_root+\"phi.\"+str(num_round)\n",
    "        else:\n",
    "            pi_file = self.model_root+\"pi.final\"\n",
    "            theta_file = self.model_root+\"theta.final\"\n",
    "            phi_file = self.model_root+\"phi.final\"\n",
    "        self.print_mat(self.log_phi, self.num_topics, self.num_words, phi_file)\n",
    "        self.print_mat(self.log_theta, self.num_tags, self.num_topics, theta_file)\n",
    "        self.print_array(self.pi, self.num_tags, pi_file)\n",
    "    \n",
    "    def print_mat(self, mat, row, col, filename):\n",
    "        outputfile = open(filename, \"w\", encoding = \"utf-8\")\n",
    "        for i in range(row):\n",
    "            for j in range(col):\n",
    "                outputfile.write(str(mat[i][j]) + \" \")\n",
    "            outputfile.write(\"\\n\")\n",
    "        outputfile.flush()\n",
    "        outputfile.close()\n",
    "        \n",
    "    def print_array(self, mat, row, filename):\n",
    "        outputfile = open(filename, \"w\", encoding = \"utf-8\")\n",
    "        for i in range(row):\n",
    "            outputfile.write(str(mat[i]) + \" \")\n",
    "        outputfile.flush()\n",
    "        outputfile.close()\n",
    "    \n",
    "    def print_model_info(self):\n",
    "        outputfile = open(self.model_root+\"model.info\", \"w\", encoding=\"utf-8\")\n",
    "        outputfile.write(\"num_tags: \" + str(self.num_tags) + \"\\n\")\n",
    "        outputfile.write(\"num_words: \" + str(self.num_words) + \"\\n\")\n",
    "        outputfile.write(\"num_topics: \" + str(self.num_topics) + \"\\n\")\n",
    "        outputfile.close()\n",
    "\n",
    "class Configuration():\n",
    "    def __init__(self, settingsfile):\n",
    "        '''\n",
    "        Constructor\n",
    "        '''\n",
    "        self.pi_learn_rate = 0.00001\n",
    "        self.max_pi_iter=100\n",
    "        self.pi_min_eps=1e-5\n",
    "        self.max_xi_iter=100\n",
    "        self.xi_min_eps=1e-5\n",
    "        self.xi_learn_rate = 10\n",
    "        self.max_em_iter=30\n",
    "        self.num_threads=1\n",
    "        self.max_var_iter=30\n",
    "        self.var_converence = 1e-6\n",
    "        self.em_converence = 1e-4\n",
    "        self.read_settingfile(settingsfile)\n",
    "        \n",
    "    def read_settingfile(self,settingsfile):\n",
    "        settingslist = open(settingsfile, \"r\", encoding = \"utf-8\")\n",
    "        for line in settingslist:\n",
    "            confname = line.split()[0]\n",
    "            confvalue = line.split()[1]\n",
    "            if confname == \"pi_learn_rate\":\n",
    "                self.pi_learn_rate = float(confvalue)\n",
    "            if confname == \"max_pi_iter\":\n",
    "                self.max_pi_iter = int(confvalue)\n",
    "            if confname == \"pi_min_eps\":\n",
    "                self.pi_min_eps = float(confvalue)\n",
    "            if confname == \"max_xi_iter\":\n",
    "                self.max_xi_iter = int(confvalue)\n",
    "            if confname == \"xi_learn_rate\":\n",
    "                self.xi_learn_rate = float(confvalue)\n",
    "            if confname == \"xi_min_eps\":\n",
    "                self.xi_min_eps = float(confvalue)\n",
    "            if confname == \"max_em_iter\":\n",
    "                self.max_em_iter = int(confvalue)\n",
    "            if confname == \"num_threads\":\n",
    "                self.num_threads = int(confvalue)\n",
    "            if confname == \"var_converence\":\n",
    "                self.var_converence = float(confvalue)\n",
    "            if confname == \"max_var_iter\":\n",
    "                self.max_var_iter = int(confvalue)\n",
    "            if confname == \"em_converence\":\n",
    "                self.em_converence = float(confvalue)\n",
    "             \n",
    "class TWTM():\n",
    "    def __init__(self,filename, num_topics, settingsfile, model_root_):\n",
    "        '''\n",
    "        Constructor\n",
    "        '''\n",
    "        self.corpus = []\n",
    "        self.num_docs=0\n",
    "        self.num_tags=0 # all the tag number in the corpus\n",
    "        self.num_words=0\n",
    "        self.num_all_words=0\n",
    "        self.num_topics = num_topics\n",
    "        self.model_root = model_root_\n",
    "        \n",
    "        self.read_data(filename)\n",
    "        self.model = Model(self.model_root, self.num_docs, self.num_words, self.num_topics,self.num_tags, self.num_all_words)\n",
    "\n",
    "        self.configuration = Configuration(settingsfile)\n",
    "        self.begin_twtm()\n",
    "        \n",
    "    def read_data(self, filename):\n",
    "        datalist = open(filename, \"r\", encoding = \"utf-8\").readlines()\n",
    "        for onedata in datalist:\n",
    "            labelslist = onedata.split(\"@\")[0]\n",
    "            print('labelslist',labelslist)\n",
    "            wordslist = onedata.split(\"@\")[1]\n",
    "            print('wordslist',wordslist)\n",
    "            doc_num_tags = int(labelslist.split()[0])\n",
    "            print('doc_num_tags',doc_num_tags)\n",
    "            tags_ptr_ = [int(m) for m in labelslist.split()[1:]] \n",
    "            num_word = int(wordslist.split()[0])\n",
    "            words = wordslist.split()[1:]\n",
    "            print('words',words)\n",
    "            tags_ptr = []\n",
    "            words_ptr = []\n",
    "            words_cnt_ptr = []\n",
    "            for t in range(doc_num_tags):\n",
    "                tags_ptr.append(int(tags_ptr_[t]))\n",
    "            if self.num_tags < max(tags_ptr):\n",
    "                self.num_tags = max(tags_ptr)\n",
    "            for i in range(num_word):\n",
    "                id_count = words[i].split(\":\")\n",
    "                words_ptr.append(int(id_count[0]))\n",
    "                words_cnt_ptr.append(int(id_count[1]))\n",
    "                self.num_all_words += words_cnt_ptr[i]\n",
    "            if self.num_words < max(words_ptr):\n",
    "                self.num_words = max(words_ptr)\n",
    "            doc = Document(doc_num_tags, num_word, self.num_topics, 100, tags_ptr_, words_ptr,words_cnt_ptr)\n",
    "            self.corpus.append(doc)\n",
    "            self.num_docs += 1\n",
    "        self.num_tags += 1\n",
    "        self.num_words +=1\n",
    "        if self.corpus[1].num_tags != len(self.corpus[1].tags_ptr):\n",
    "            print(\"the number of tags in a documet doesn't equal with its ptr..\")\n",
    "            exit(0)\n",
    "        if self.corpus[1].num_words != len(self.corpus[1].words_ptr):\n",
    "            print(\"the number of words in a documet doesn't equal with its ptr..\")\n",
    "        #     \n",
    "        print(\"num_docs: \"+str(self.num_docs)+\", num_tags: \"+str(self.num_tags)+\", num_words: \"+str(self.num_words)+\" \\n\")\n",
    "    \n",
    "    def save_parameters_docs(self, num_round):\n",
    "        if num_round != -1:\n",
    "            xi_file = self.model.model_root+\"xi.\"+str(num_round)\n",
    "            topic_dis_file = self.model.model_root+\"topic_dis_docs.\"+str(num_round)\n",
    "        else:\n",
    "            xi_file = self.model.model_root+\"xi.final\"\n",
    "            topic_dis_file = self.model.model_root+\"topic_dis_docs.final\"\n",
    "        xi_fp = open(xi_file, \"w\", encoding = \"utf-8\")\n",
    "        topic_dis_fp = open(topic_dis_file,\"w\", encoding = \"utf-8\")\n",
    "        \n",
    "        for doc in self.corpus:\n",
    "            for i in range(doc.num_tags):\n",
    "                xi_fp.write(str(doc.tags_ptr[i]) +\":\"+ str(doc.xi[i]))\n",
    "            xi_fp.write(\"\\n\")\n",
    "            \n",
    "            for k in range(self.num_topics):\n",
    "                topic_dis_fp.write(str(doc.topic[k]) + ' ')\n",
    "            topic_dis_fp.write(\"\\n\")\n",
    "            \n",
    "        xi_fp.close()\n",
    "        topic_dis_fp.close()\n",
    "    \n",
    "    def likelihood(self):\n",
    "        lik = 0.0 \n",
    "        for d in range(self.num_docs):\n",
    "            temp_lik, return_doc = self.compute_doc_likelihood(self.corpus[d])\n",
    "            lik += temp_lik\n",
    "            #self.corpus[d].lik = temp_lik\n",
    "        return lik\n",
    "    \n",
    "    def splitlikelihood(self, dataSplit, likreturn_dataSplit, likreturn_dataSplit_likvalue):\n",
    "        splitlen = len(dataSplit)\n",
    "        for d in range(splitlen):\n",
    "            temp_lik, return_doc = self.compute_doc_likelihood(dataSplit[d])\n",
    "            likreturn_dataSplit_likvalue.value += temp_lik\n",
    "            likreturn_dataSplit.append(return_doc)\n",
    "    \n",
    "    def run_multiprocesses_likelihood(self):\n",
    "        lik = 0.0\n",
    "        workers = []\n",
    "        workers_no = self.configuration.num_threads\n",
    "        corpusSplitlist = self.split_average_data(workers_no)\n",
    "        \n",
    "        likmanager = Manager()\n",
    "        ManagerReturn_corpusSplitlist = []\n",
    "        ManagerReturn_corpusSplitlist_lik = []\n",
    "        for dataSplit in corpusSplitlist:\n",
    "            likreturn_dataSplit = likmanager.list()\n",
    "            likreturn_dataSplit_likvalue = likmanager.Value(\"\",0.0)\n",
    "            worker = Process(target=self.splitlikelihood, args=(dataSplit, likreturn_dataSplit, likreturn_dataSplit_likvalue))\n",
    "            worker.start()\n",
    "            workers.append(worker)\n",
    "            ManagerReturn_corpusSplitlist.append(likreturn_dataSplit)\n",
    "            ManagerReturn_corpusSplitlist_lik.append(likreturn_dataSplit_likvalue)\n",
    "        for w in workers:\n",
    "            w.join()\n",
    "        \n",
    "        # compute all the likelihood for the splits:\n",
    "        for v in ManagerReturn_corpusSplitlist_lik:\n",
    "            lik += v.value\n",
    "        # update all the docs into corpus, since we compute the doc distribution in likelihood()\n",
    "        self.corpus.clear()\n",
    "        for dataSplit in ManagerReturn_corpusSplitlist:\n",
    "            for doc in dataSplit:\n",
    "                self.corpus.append(doc)\n",
    "        \n",
    "        return lik\n",
    "    \n",
    "    def get_pi_function(self):\n",
    "        pi_function_value = 0.0\n",
    "        num_docs = self.model.num_docs\n",
    "        pi = self.model.pi\n",
    "        for d in range(num_docs):\n",
    "            sigma_pi = 0.0\n",
    "            sigma_xi = 0.0\n",
    "            doc = self.corpus[d]\n",
    "            for i in range(doc.num_tags):\n",
    "                sigma_pi += pi[doc.tags_ptr[i]]\n",
    "                sigma_xi += doc.xi[i]\n",
    "            pi_function_value += log_gamma(sigma_pi)\n",
    "            for i in range(doc.num_tags):\n",
    "                tagid = doc.tags_ptr[i]\n",
    "                pi_function_value -= log_gamma(pi[tagid])\n",
    "                pi_function_value += (pi[tagid] -1) * (digamma(doc.xi[i]) - digamma(sigma_xi) )\n",
    "        return pi_function_value\n",
    "    \n",
    "    def get_descent_pi(self):\n",
    "        num_tags = self.model.num_tags\n",
    "        num_docs = self.model.num_docs\n",
    "        descent_pi = [0.0 for i in range(num_tags)]\n",
    "        pi = self.model.pi\n",
    "        for d in range(num_docs):\n",
    "            sigma_pi = 0.0\n",
    "            doc = self.corpus[d]\n",
    "            doc_num_tags = doc.num_tags\n",
    "            sigma_xi = 0.0\n",
    "            for i in range(doc_num_tags):\n",
    "                sigma_pi += pi[doc.tags_ptr[i]]\n",
    "                sigma_xi += doc.xi[i]\n",
    "            for i in range(doc_num_tags):\n",
    "                tagid = doc.tags_ptr[i]\n",
    "                pis = pi[tagid]\n",
    "                descent_pi[tagid] += digamma(sigma_pi) - digamma(pis) + digamma(doc.xi[i]) - digamma(sigma_xi)\n",
    "        return descent_pi\n",
    "    \n",
    "    def learn_pi(self):\n",
    "        num_round = 0\n",
    "        num_tags = self.model.num_tags\n",
    "        last_pi = [0.0 for i in range(num_tags)]\n",
    "        descent_pi = [0.0 for i in range(num_tags)]\n",
    "        #\n",
    "        z = -1\n",
    "        num_wait_for_z = 0\n",
    "        while z < 0 and num_wait_for_z <=20:\n",
    "            for i in range(num_tags):\n",
    "                self.model.pi[i] = random.random() *2\n",
    "            z = self.get_pi_function()\n",
    "            #print(\"wait for z >=0 \\n\")\n",
    "            num_wait_for_z += 1\n",
    "        #    \n",
    "        last_z = 0\n",
    "        learn_rate = self.configuration.pi_learn_rate\n",
    "        eps =10000\n",
    "        max_pi_iter = self.configuration.max_pi_iter\n",
    "        pi_min_eps = self.configuration.pi_min_eps\n",
    "        has_neg_value_flag = False\n",
    "        while num_round < max_pi_iter and eps > pi_min_eps:\n",
    "            last_z = z\n",
    "            last_pi = copy.deepcopy(self.model.pi)\n",
    "            descent_pi = self.get_descent_pi()\n",
    "            for i in range(num_tags):\n",
    "                self.model.pi[i] += learn_rate * descent_pi[i]\n",
    "                if self.model.pi[i] <0:\n",
    "                    has_neg_value_flag = True\n",
    "            z = self.get_pi_function()\n",
    "            if has_neg_value_flag or last_z > z:\n",
    "                learn_rate *= 0.5\n",
    "                z = last_z\n",
    "                self.model.pi = copy.deepcopy(last_pi)\n",
    "                eps = 1000.0\n",
    "            else:\n",
    "                eps = norm2(last_pi, self.model.pi, num_tags)\n",
    "            num_round +=1\n",
    "    \n",
    "    def learn_theta_phi(self):\n",
    "        num_docs = self.model.num_docs\n",
    "        num_topics = self.model.num_topics\n",
    "        num_words = self.model.num_words\n",
    "        num_tags = self.model.num_tags\n",
    "        reset_theta_flag = np.full(shape = (num_tags, num_topics),  dtype = bool, fill_value = False)\n",
    "        reset_phi_flag = np.full(shape = (num_topics, num_words),  dtype = bool, fill_value = False)\n",
    "        for d in range(num_docs):\n",
    "            doc = self.corpus[d]\n",
    "            doc_num_tags = doc.num_tags\n",
    "            doc_num_words = doc.num_words\n",
    "            sigma_xi = 0\n",
    "            for i in range(doc_num_tags):\n",
    "                sigma_xi += doc.xi[i]\n",
    "            for i in range(doc_num_tags):\n",
    "                tagid = doc.tags_ptr[i]\n",
    "                for k in range(num_topics):\n",
    "                    for j in range(doc_num_words):\n",
    "                        if reset_theta_flag[tagid][k] is False:\n",
    "                            reset_theta_flag[tagid][k] = True\n",
    "                            self.model.log_theta[tagid][k] = log(doc.words_cnt_ptr[j]) + doc.log_gamma[j][k] + log(doc.xi[i]) - log(sigma_xi)\n",
    "                        else:\n",
    "                            self.model.log_theta[tagid][k] = log_sum(self.model.log_theta[tagid][k], log(doc.words_cnt_ptr[j]) + doc.log_gamma[j][k] + log(doc.xi[i]) - log(sigma_xi) )\n",
    "            for k in range(num_topics):\n",
    "                for i in range(doc_num_words):\n",
    "                    wordid = doc.words_ptr[i]\n",
    "                    if reset_phi_flag[k][wordid] is False:\n",
    "                        reset_phi_flag[k][wordid] = True\n",
    "                        self.model.log_phi[k][wordid] = log(doc.words_cnt_ptr[i]) + doc.log_gamma[i][k]\n",
    "                    else:\n",
    "                        self.model.log_phi[k][wordid] = log_sum(self.model.log_phi[k][wordid], log(doc.words_cnt_ptr[i]) + doc.log_gamma[i][k])\n",
    "        \n",
    "        #\n",
    "        self.normalize_log_matrix_rows(self.model.log_theta, num_tags, num_topics)\n",
    "        self.normalize_log_matrix_rows(self.model.log_phi, num_topics, num_words)\n",
    "        pass\n",
    "    \n",
    "    def normalize_log_matrix_rows(self, log_mat, rows, cols):\n",
    "        for i in range(rows):\n",
    "            temp = log_mat[i][0]\n",
    "            for j in range(cols-1):\n",
    "                temp = log_sum(temp, log_mat[i][j+1])\n",
    "            for j in range(cols):\n",
    "                log_mat[i][j] -= temp\n",
    "    \n",
    "    def get_xi_function(self, doc):\n",
    "        xi_function_value = 0.0\n",
    "        num_tags = doc.num_tags\n",
    "        sigma_xi = 0\n",
    "        pi = self.model.pi\n",
    "        log_theta = self.model.log_theta\n",
    "        for i in range(num_tags):\n",
    "            sigma_xi += doc.xi[i]\n",
    "        for i in range(num_tags):\n",
    "            xi_function_value += (pi[doc.tags_ptr[i]] - doc.xi[i]) * (digamma(doc.xi[i]) - digamma(sigma_xi)) + log_gamma(doc.xi[i])\n",
    "        xi_function_value -= log_gamma(sigma_xi)\n",
    "        doc_num_words = doc.num_words\n",
    "        num_topics = self.model.num_topics\n",
    "        sum_log_theta = [0 for i in range(num_topics)]\n",
    "        for k in range(num_topics):\n",
    "            temp = 0\n",
    "            for j in range(num_tags):\n",
    "                temp += log_theta[doc.tags_ptr[j]][k] * doc.xi[j] / sigma_xi\n",
    "                sum_log_theta[k] = temp\n",
    "        for i in range(doc_num_words):\n",
    "            for k in range(num_topics):\n",
    "                xi_function_value +=  sum_log_theta[k] * exp(doc.log_gamma[i][k]) * doc.words_cnt_ptr[i]\n",
    "        return xi_function_value\n",
    "    \n",
    "    def get_descent_xi(self, doc):\n",
    "        sigma_xi = 0.0\n",
    "        sigma_pi = 0.0\n",
    "        num_tags = doc.num_tags\n",
    "        descent_xi = [0 for i in range(num_tags)]\n",
    "        for i in range(num_tags):\n",
    "            sigma_xi += doc.xi[i]\n",
    "            sigma_pi += self.model.pi[doc.tags_ptr[i]]\n",
    "        \n",
    "        for i in range(num_tags):\n",
    "            descent_xi[i] = trigamma(doc.xi[i]) * ( self.model.pi[doc.tags_ptr[i]] - doc.xi[i])\n",
    "            descent_xi[i] -= trigamma(sigma_xi) * (sigma_pi - sigma_xi)\n",
    "        \n",
    "        doc_num_words = doc.num_words\n",
    "        num_topic = self.num_topics\n",
    "        log_theta =self.model.log_theta\n",
    "        sum_log_theta = [0.0 for i in range(num_topic)]\n",
    "        for k in range(num_topic):\n",
    "            for i in range(num_tags):\n",
    "                tag_id = doc.tags_ptr[i]\n",
    "                sum_log_theta[k] += log_theta[tag_id][k] * doc.xi[i]\n",
    "       \n",
    "        sum_gamma_array = [0.0 for i in range(num_topic)]\n",
    "        for k in range(num_topic):\n",
    "            sum_gamma_array[k] = 0\n",
    "            for i in range(doc_num_words):\n",
    "                sum_gamma_array[k] += exp(doc.log_gamma[i][k]) * doc.words_cnt_ptr[i]\n",
    "        \n",
    "        for j in range(num_tags):\n",
    "            for k in range(num_topic):\n",
    "                temp = 0\n",
    "                temp += log_theta[doc.tags_ptr[j]][k] * sigma_xi\n",
    "                temp -= sum_log_theta[k]\n",
    "                temp = sum_gamma_array[k] * (temp/(sigma_xi * sigma_xi))\n",
    "                descent_xi[j] += temp\n",
    "        \n",
    "        return descent_xi\n",
    "        \n",
    "    \n",
    "    def inference_xi(self, doc):\n",
    "        num_tags = doc.num_tags\n",
    "        # init_xi\n",
    "        for i in range(num_tags):\n",
    "            doc.xi[i] = random.random()\n",
    "        z = 0\n",
    "        learn_rate = self.configuration.xi_learn_rate\n",
    "        eps = 10000\n",
    "        num_round =0\n",
    "        max_xi_iter = self.configuration.max_xi_iter\n",
    "        xi_min_eps = self.configuration.xi_min_eps\n",
    "        last_z = 0\n",
    "        last_xi = []\n",
    "        while num_round < max_xi_iter and eps > xi_min_eps:\n",
    "            z = self.get_xi_function(doc)\n",
    "            last_z = z\n",
    "            last_xi = copy.deepcopy(doc.xi)\n",
    "            descent_xi =self.get_descent_xi(doc)\n",
    "            has_neg_value_flag = False\n",
    "            for i in range(num_tags):\n",
    "                doc.xi[i] += learn_rate * descent_xi[i]\n",
    "                if doc.xi[i] < 0:\n",
    "                    has_neg_value_flag = True\n",
    "           \n",
    "            if has_neg_value_flag is True or last_z > self.get_xi_function(doc):\n",
    "                learn_rate *= 0.2\n",
    "                z = last_z\n",
    "                eps = 10000\n",
    "                doc.xi = copy.deepcopy(last_xi)\n",
    "            else:\n",
    "                eps = norm2(last_xi, doc.xi, num_tags)\n",
    "            num_round += 1\n",
    "    \n",
    "    def inference_gamma(self, doc):\n",
    "        log_theta = self.model.log_theta\n",
    "        log_phi = self.model.log_phi\n",
    "        num_tags = doc.num_tags\n",
    "        num_topics = self.num_topics\n",
    "        doc_num_words = doc.num_words\n",
    "        log_gamma = doc.log_gamma\n",
    "        theta_xi = [0.0 for k in range(num_topics)]\n",
    "        sigma_xi = 0\n",
    "        for i in range(num_tags):\n",
    "            sigma_xi += doc.xi[i]\n",
    "        \n",
    "        for k in range(num_topics):\n",
    "            temp = 0.0\n",
    "            for i in range(num_tags):\n",
    "                temp+= doc.xi[i] / sigma_xi * log_theta[doc.tags_ptr[i]][k]\n",
    "            theta_xi[k] = temp\n",
    "        \n",
    "        for i in range(doc_num_words):\n",
    "            wordid = doc.words_ptr[i]\n",
    "            sum_log_gamma = 0\n",
    "            for k in range(num_topics):\n",
    "                temp = log_phi[k][wordid] + theta_xi[k]\n",
    "                log_gamma[i][k] = temp\n",
    "                if k ==0:\n",
    "                    sum_log_gamma = temp\n",
    "                else:\n",
    "                    sum_log_gamma = log_sum(sum_log_gamma, temp)\n",
    "            for k in range(num_topics):\n",
    "                log_gamma[i][k] -= sum_log_gamma\n",
    "        pass\n",
    "    \n",
    "    def compute_doc_likelihood(self, doc):\n",
    "        log_topic = doc.topic\n",
    "        log_theta = self.model.log_theta\n",
    "        log_phi = self.model.log_phi\n",
    "        num_topics = self.num_topics\n",
    "        reset_log_topic = [False for i in range(num_topics)]\n",
    "        for k in range(num_topics):\n",
    "            log_topic[k] = 0\n",
    "        sigma_xi = 0\n",
    "        xi = doc.xi\n",
    "        doc_num_tags = doc.num_tags\n",
    "        lik = 0.0 \n",
    "        for i in range(doc_num_tags):\n",
    "            sigma_xi += xi[i]\n",
    "        \n",
    "        for i in range(doc_num_tags):\n",
    "            tagid = doc.tags_ptr[i]\n",
    "            for k in range(num_topics):\n",
    "                if reset_log_topic[k] is False:\n",
    "                    log_topic[k] = log_theta[tagid][k] + log(xi[i]) - log(sigma_xi)\n",
    "                    reset_log_topic[k] = True\n",
    "                else:\n",
    "                    log_topic[k] = log_sum(log_topic[k],  log_theta[tagid][k] + log(xi[i]) - log(sigma_xi))\n",
    "        \n",
    "        doc_num_words = doc.num_words\n",
    "        for i in range(doc_num_words):\n",
    "            temp = 0\n",
    "            wordid = doc.words_ptr[i]\n",
    "            temp = log_topic[0] + log_phi[0][wordid]\n",
    "            for k in range(num_topics-1):\n",
    "                temp = log_sum(temp, log_topic[k+1] + log_phi[k+1][wordid])\n",
    "                # because 0 is already added, so from k+1\n",
    "            lik += temp * doc.words_cnt_ptr[i]\n",
    "        \n",
    "        doc.lik = lik\n",
    "        return lik, doc\n",
    "    \n",
    "    def inference(self, doc):\n",
    "        var_iter =0\n",
    "        lik_old = -10000000\n",
    "        converged = 1\n",
    "        lik = 0\n",
    "        while (converged > self.configuration.var_converence) and var_iter < self.configuration.max_var_iter:\n",
    "            var_iter += 1\n",
    "            self.inference_xi(doc)\n",
    "            self.inference_gamma(doc)\n",
    "            lik, return_doc = self.compute_doc_likelihood(doc)\n",
    "            converged = (lik_old - lik) / lik_old\n",
    "            lik_old = lik\n",
    "        return doc\n",
    "\n",
    "    def inferenceDatasplit(self, datasplit, managerDoclist):\n",
    "        datasize = len(datasplit)\n",
    "        for i in range(datasize):\n",
    "            doc = self.inference(datasplit[i])\n",
    "            managerDoclist.append(doc)\n",
    "        \n",
    "    def split_average_data(self, thread_no):\n",
    "        fn = len(self.corpus)//thread_no\n",
    "        rn = len(self.corpus)%thread_no\n",
    "        ar = [fn+1]*rn+ [fn]*(thread_no-rn)\n",
    "        si = [i*(fn+1) if i<rn else (rn*(fn+1)+(i-rn)*fn) for i in range(thread_no)]\n",
    "        corpusSplitlist = [self.corpus[si[i]:si[i]+ar[i]] for i in range(thread_no)]\n",
    "        return corpusSplitlist\n",
    "    \n",
    "    def run_multiprocesses_inference(self):\n",
    "        workers = []\n",
    "        workers_no = self.configuration.num_threads\n",
    "        corpusSplitlist = self.split_average_data(workers_no)\n",
    "        manager = Manager()\n",
    "        ManagerReturn_corpusSplitlist = []\n",
    "        for dataSplit in corpusSplitlist:\n",
    "            return_dataSplit = manager.list()\n",
    "            worker = Process(target=self.inferenceDatasplit, args=(dataSplit, return_dataSplit))\n",
    "            worker.start()\n",
    "            workers.append(worker)\n",
    "            ManagerReturn_corpusSplitlist.append(return_dataSplit)\n",
    "        for w in workers:\n",
    "            w.join()\n",
    "        \n",
    "        self.corpus.clear()\n",
    "        # after all the processes, update the corpus using the ManagerReturn_corpusSplitlist\n",
    "        for dataSplit in ManagerReturn_corpusSplitlist:\n",
    "            for doc in dataSplit:\n",
    "                self.corpus.append(doc)\n",
    "    \n",
    "    def begin_twtm(self):\n",
    "        self.model.print_model_info()\n",
    "        learn_begin_time = time.time()\n",
    "        num_round = 0\n",
    "        print(\"compute the likelihood...\")\n",
    "        #lik1 = self.likelihood() \n",
    "        lik = self.run_multiprocesses_likelihood() \n",
    "\n",
    "        plik = 0.0\n",
    "        likehood_record = []\n",
    "        likehood_record.append(lik)\n",
    "        converged = 1\n",
    "        while num_round < self.configuration.max_em_iter and (converged < 0 or converged > self.configuration.em_converence):\n",
    "            cur_round_begin_time = time.time()\n",
    "            plik = lik\n",
    "            print(\"Round %d begin... \"%num_round)\n",
    "            print(\"inference...\")\n",
    "            self.run_multiprocesses_inference()\n",
    "            print(\"learn pi .... \")\n",
    "            self.learn_pi()\n",
    "            print(\"learn theta .... \")\n",
    "            self.learn_theta_phi()\n",
    "            print(\"compute the likelihood...\")\n",
    "            lik = self.run_multiprocesses_likelihood()\n",
    "            perplexity = exp(-lik/self.model.num_all_words)\n",
    "            converged = (plik - lik) / plik\n",
    "            if converged < 0:\n",
    "                self.configuration.max_var_iter *=2\n",
    "            cur_round_cost_time = time.time() - cur_round_begin_time\n",
    "            print(\"Round \"+str(num_round)+\" : likehood= \"+str(lik)+\" . last_likehood= \"+str(plik)+\" . perplexity= \"+str(perplexity)+\" converged= \"+str(converged)+\" . cost_time= \"+str(cur_round_cost_time)+\" secs.\\n\")\n",
    "            num_round += 1\n",
    "            likehood_record.append(lik)\n",
    "            if num_round % 10 ==0:\n",
    "                self.model.save_model(num_round)\n",
    "                self.save_parameters_docs(num_round)\n",
    "            \n",
    "        learn_cost_time = time.time() - learn_begin_time\n",
    "        print(\"All the round learning is over, and cost %f seconds.\"%learn_cost_time)\n",
    "        self.model.save_model(-1)\n",
    "        self.save_parameters_docs(-1)\n",
    "    \n",
    "    def infer_twtm(self):\n",
    "        pass\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_docs: 9673, num_tags: 3654, num_words: 52274 \n",
      "\n",
      "compute the likelihood...\n",
      "Round 0 begin... \n",
      "inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-14:\n",
      "Process Process-22:\n",
      "Process Process-16:\n",
      "Process Process-21:\n",
      "Process Process-19:\n",
      "Process Process-15:\n",
      "Process Process-20:\n",
      "Process Process-18:\n",
      "Process Process-17:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-13:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 620, in inferenceDatasplit\n",
      "    doc = self.inference(datasplit[i])\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 620, in inferenceDatasplit\n",
      "    doc = self.inference(datasplit[i])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 620, in inferenceDatasplit\n",
      "    doc = self.inference(datasplit[i])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 620, in inferenceDatasplit\n",
      "    doc = self.inference(datasplit[i])\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 610, in inference\n",
      "    self.inference_xi(doc)\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 610, in inference\n",
      "    self.inference_xi(doc)\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 620, in inferenceDatasplit\n",
      "    doc = self.inference(datasplit[i])\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 620, in inferenceDatasplit\n",
      "    doc = self.inference(datasplit[i])\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 610, in inference\n",
      "    self.inference_xi(doc)\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 620, in inferenceDatasplit\n",
      "    doc = self.inference(datasplit[i])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 620, in inferenceDatasplit\n",
      "    doc = self.inference(datasplit[i])\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 610, in inference\n",
      "    self.inference_xi(doc)\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 515, in inference_xi\n",
      "    z = self.get_xi_function(doc)\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 525, in inference_xi\n",
      "    if has_neg_value_flag is True or last_z > self.get_xi_function(doc):\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 610, in inference\n",
      "    self.inference_xi(doc)\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 620, in inferenceDatasplit\n",
      "    doc = self.inference(datasplit[i])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 610, in inference\n",
      "    self.inference_xi(doc)\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 610, in inference\n",
      "    self.inference_xi(doc)\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 518, in inference_xi\n",
      "    descent_xi =self.get_descent_xi(doc)\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 610, in inference\n",
      "    self.inference_xi(doc)\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 459, in get_xi_function\n",
      "    xi_function_value +=  sum_log_theta[k] * exp(doc.log_gamma[i][k]) * doc.words_cnt_ptr[i]\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 610, in inference\n",
      "    self.inference_xi(doc)\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 488, in get_descent_xi\n",
      "    sum_gamma_array[k] += exp(doc.log_gamma[i][k]) * doc.words_cnt_ptr[i]\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 525, in inference_xi\n",
      "    if has_neg_value_flag is True or last_z > self.get_xi_function(doc):\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 515, in inference_xi\n",
      "    z = self.get_xi_function(doc)\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 447, in get_xi_function\n",
      "    xi_function_value += (pi[doc.tags_ptr[i]] - doc.xi[i]) * (digamma(doc.xi[i]) - digamma(sigma_xi)) + log_gamma(doc.xi[i])\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 525, in inference_xi\n",
      "    if has_neg_value_flag is True or last_z > self.get_xi_function(doc):\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 518, in inference_xi\n",
      "    descent_xi =self.get_descent_xi(doc)\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 515, in inference_xi\n",
      "    z = self.get_xi_function(doc)\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 518, in inference_xi\n",
      "    descent_xi =self.get_descent_xi(doc)\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 447, in get_xi_function\n",
      "    xi_function_value += (pi[doc.tags_ptr[i]] - doc.xi[i]) * (digamma(doc.xi[i]) - digamma(sigma_xi)) + log_gamma(doc.xi[i])\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 459, in get_xi_function\n",
      "    xi_function_value +=  sum_log_theta[k] * exp(doc.log_gamma[i][k]) * doc.words_cnt_ptr[i]\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 488, in get_descent_xi\n",
      "    sum_gamma_array[k] += exp(doc.log_gamma[i][k]) * doc.words_cnt_ptr[i]\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 459, in get_xi_function\n",
      "    xi_function_value +=  sum_log_theta[k] * exp(doc.log_gamma[i][k]) * doc.words_cnt_ptr[i]\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 620, in inferenceDatasplit\n",
      "    doc = self.inference(datasplit[i])\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 44, in digamma\n",
      "    return r + log(x) - 0.5 / x + t\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 44, in digamma\n",
      "    return r + log(x) - 0.5 / x + t\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 610, in inference\n",
      "    self.inference_xi(doc)\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 459, in get_xi_function\n",
      "    xi_function_value +=  sum_log_theta[k] * exp(doc.log_gamma[i][k]) * doc.words_cnt_ptr[i]\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 447, in get_xi_function\n",
      "    xi_function_value += (pi[doc.tags_ptr[i]] - doc.xi[i]) * (digamma(doc.xi[i]) - digamma(sigma_xi)) + log_gamma(doc.xi[i])\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 488, in get_descent_xi\n",
      "    sum_gamma_array[k] += exp(doc.log_gamma[i][k]) * doc.words_cnt_ptr[i]\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 515, in inference_xi\n",
      "    z = self.get_xi_function(doc)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-1-82e476eb9af8>\", line 36, in log_gamma\n",
      "    return tmp + log(ser * sqrt(2 * PI))\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5dc4f182afe6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_root\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mTWTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettingsfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-82e476eb9af8>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, num_topics, settingsfile, model_root_)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfiguration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfiguration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettingsfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_twtm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-82e476eb9af8>\u001b[0m in \u001b[0;36mbegin_twtm\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Round %d begin... \"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mnum_round\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inference...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_multiprocesses_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"learn pi .... \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_pi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-82e476eb9af8>\u001b[0m in \u001b[0;36mrun_multiprocesses_inference\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0mManagerReturn_corpusSplitlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_dataSplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                     \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# python3.6 twtm.py est ../demo/twtm.demo.input setting.txt 10 ./output\n",
    "inputfile = './demo/twtm.demo.input' #sys.argv[2]\n",
    "settingsfile = 'setting.txt'#sys.argv[3]\n",
    "num_topics = 10#int(sys.argv[4])\n",
    "model_root = './output'#sys.argv[5]\n",
    "if model_root.endswith(\"/\") is False:\n",
    "    model_root = model_root+\"/\"\n",
    "\n",
    "TWTM(inputfile, num_topics, settingsfile, model_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
